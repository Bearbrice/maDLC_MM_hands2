{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COLAB_maDLC_TrainNetwork_VideoAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bearbrice/maDLC_MM_hands2/blob/main/examples/COLAB_maDLC_TrainNetwork_VideoAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK255E7YoEIt"
      },
      "source": [
        "# DeepLabCut 2.2 Toolbox - COLAB\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590444465547-SHXODUII311HEE407IL6/ke17ZwdGBToddI8pDm48kE4VnnB9_j2k1VP236ADqAFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQg9Vf0owGyf3dhfDKy8SxMujaKmp2B54Sb3VS1rO76Whq-cUhHVuKFlGUXsU9tJk/ezgif.com-video-to-gif.gif?format=1500w)\n",
        "\n",
        "https://github.com/DeepLabCut/DeepLabCut\n",
        "\n",
        "This notebook illustrates how to, for multi-animal projects, use the cloud-based GPU to:\n",
        "- create a multi-animal training set\n",
        "- train a network\n",
        "- evaluate a network\n",
        "- cross evaluate inference parameters\n",
        "- analyze novel videos\n",
        "- assemble tracklets\n",
        "- create quality check plots\n",
        "\n",
        "###This notebook assumes you already have a project folder with labeled data! \n",
        "\n",
        "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
        "\n",
        "This shows the most simple code to do so, but many of the functions have additional features, so please check out the docs on GitHub.\n",
        "\n",
        "Mathis et al, in prep. <- please note, we are providing this toolbox as an early access release; more feeatures and details will be released with the forthcoming paper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txoddlM8hLKm"
      },
      "source": [
        "## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q23BzhA6CXxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73dec4f6-d828-4c31-898a-0a1758524de3"
      },
      "source": [
        "#(this will take a few minutes to install all the dependences!)\n",
        "!#pip install deeplabcut\n",
        "!pip install 'deeplabcut[gui]'==2.2rc3\n",
        "%reload_ext numpy\n",
        "%reload_ext scipy\n",
        "%reload_ext matplotlib\n",
        "%reload_ext mpl_toolkits"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeplabcut\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/fc/b5774e22a3eeaac1e1ca5670aa2281a5c408c9abc25f51e53e3f2525aebd/deeplabcut-2.1.10.4-py3-none-any.whl (695kB)\n",
            "\u001b[K     |████████████████████████████████| 696kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (5.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (4.41.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.36.2)\n",
            "Collecting filterpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/ac8914360460fafa1990890259b7fa5ef7ba4cd59014e782e4ab3ab144d8/filterpy-1.4.5.zip (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 27.2MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/9b/35ab3469fd1509f7636a344940569ebfd33239673fd2318e80b4700a257c/matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 210kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (57.0.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2021.5.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.22.2.post1)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2021.3.0)\n",
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Collecting numba==0.51.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/f3/a32d3bc3d23923228e49276bbc1bdce3763dd19a299c4b4164d83bb5989f/numba-0.51.1-cp37-cp37m-manylinux2014_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 33.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.1.5)\n",
            "Collecting opencv-python-headless~=3.4.9.33\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/1c/5544e626593158c6a23599f40193464121526e45aa470001a8113e45d9b8/opencv_python_headless-3.4.9.33-cp37-cp37m-manylinux1_x86_64.whl (21.6MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6MB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.4.1)\n",
            "Collecting numpy~=1.17.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/51/20098150b6108061cb7542af3de7bfcfe0182bca21613697153e49dc4adc/numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 40.2MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml>=0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/57/19361b93542a1bb071fe8b7dd5ae792de6e8ab86c707aa2c44db08c60b99/ruamel.yaml-0.17.10-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.13)\n",
            "Collecting scikit-image>=0.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/d9/d738fdb4954575fb631b9c7a2eaa59df3ab8b7f3c2fc28a37259a42d8a49/scikit_image-0.18.2-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2MB 107kB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.0)\n",
            "Requirement already satisfied: moviepy<=1.0.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.15.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.29.23)\n",
            "Collecting tensorpack==0.9.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/cb/62dc9115722a0b4fbeca6275ffbe47118149171ffafa7d1db6e295453aae/tensorpack-0.9.8-py2.py3-none-any.whl (288kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.4.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.1.0)\n",
            "Collecting statsmodels>=0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/69/8eef30a6237c54f3c0b524140e2975f4b1eea3489b45eb3339574fc8acee/statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 20.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->deeplabcut) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->deeplabcut) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->deeplabcut) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deeplabcut) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba==0.51.1->deeplabcut) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->deeplabcut) (2018.9)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/8a/ba37489b423916162b086b01c7c18001cf297350694180468e1698085c58/ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (2021.7.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17->deeplabcut) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug->deeplabcut) (1.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->deeplabcut) (4.1.2.30)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (1.0.2)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (5.4.8)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/19/05/05b8d7c69c6abb36a34325cc3150089bdafc359f0a81fb998d93c5d5c737/msgpack_numpy-0.4.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (22.1.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack==0.9.8->deeplabcut) (0.8.9)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from tables->deeplabcut) (2.7.3)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->deeplabcut) (1.5.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->deeplabcut) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->deeplabcut) (0.2.5)\n",
            "Building wheels for collected packages: filterpy, bayesian-optimization\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-cp37-none-any.whl size=110476 sha256=b5c03f3fd807ced85ceefba8f9ba79d950f54502279e5880b80f2f868bc1e499\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/0c/dd/e92392c3f38a41371602d99fc77d6c1d42aadbf0c6afccdd02\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11686 sha256=de5f9a7ed6f28698e7c6a5f5d4f89c94a857ffd98b3cf1ac1f0224fbd92c9332\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built filterpy bayesian-optimization\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.17.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.17.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, matplotlib, filterpy, bayesian-optimization, numba, opencv-python-headless, ruamel.yaml.clib, ruamel.yaml, scikit-image, msgpack-numpy, tensorpack, statsmodels, deeplabcut\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed bayesian-optimization-1.2.0 deeplabcut-2.1.10.4 filterpy-1.4.5 matplotlib-3.1.3 msgpack-numpy-0.4.7.1 numba-0.51.1 numpy-1.17.5 opencv-python-headless-3.4.9.33 ruamel.yaml-0.17.10 ruamel.yaml.clib-0.2.6 scikit-image-0.18.2 statsmodels-0.12.2 tensorpack-0.9.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTwAcbq2-FZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f445491-0d0e-4bb4-da1f-a76e838927c1"
      },
      "source": [
        "# Use TensorFlow 1.x:\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "#GUIs don't work on the cloud, so we supress them:\n",
        "import os\n",
        "os.environ[\"DLClight\"]=\"True\"\n",
        "import deeplabcut"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ-nlTkri4HZ"
      },
      "source": [
        "# GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS4Q4UkR9rgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182b9d3a-d48e-498d-b39a-30d55adc9af8"
      },
      "source": [
        "# Clone the github repository\n",
        "!git clone -l -s git://github.com/Bearbrice/maDLC_MM_hands2.git\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'maDLC_MM_hands2'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 173, done.\u001b[K\n",
            "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 173 (delta 14), reused 160 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (173/173), 45.48 MiB | 14.15 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "maDLC_MM_hands2  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frnj1RVDyEqs"
      },
      "source": [
        "## YOU WILL NEED TO EDIT THE PROJECT PATH **in the config.yaml file** TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
        "\n",
        "Now, you can do this within COLAB! Simply navigate in the left panel to your project folder, double click on the config.yaml file, and you will see it load on the right! Edit the first part of your path, to match:\n",
        "\n",
        " /content/drive/My Drive/yourProjectFolderName\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhENAlQnFENJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "30729b71-20bc-4dff-f7d7-276af3bb3dc0"
      },
      "source": [
        "# PLEASE EDIT THIS:\n",
        "VideoType = 'mp4' #, mp4, MOV, or avi, whatever you uploaded!\n",
        "\n",
        "\n",
        "# No need to edit this, we are going to assume you put videos you want to analyze in the \"videos\" folder, but if this is NOT true, edit below:\n",
        "videofile_path = ['/content/maDLC_MM_hands2/Inference_videos'] #Enter the list of videos or folder to analyze.\n",
        "videofile_path\n",
        "\n",
        "\n",
        "#No need to edit this, as you set it when you passed the ProjectFolderName (above): \n",
        "path_config_file = '/content/maDLC_MM_hands2/maDLC_MM_hands-Brice-2021-07-08/config.yaml'\n",
        "path_config_file\n",
        "#This creates a path variable that links to your google drive project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/maDLC_MM_hands2/maDLC_MM_hands-Brice-2021-07-08/config.yaml'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNi9s1dboEJN"
      },
      "source": [
        "## Create a multi-animal training dataset:\n",
        "### You must do this step inside of Colab:\n",
        "\n",
        "- Reminder: you must connect EVERY bodypart in a skeleton before you run this step! You should OVER CONNECT all the parts for training. You can do this in the GUI before you upload your project (and in the future this will be automatically done).\n",
        "\n",
        "See docs for crucial details on how to do this effciently: https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/functionDetails.md#b-configure-the-project-\n",
        "\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589256735280-SCN7CROSJNJWCDS6EK5T/ke17ZwdGBToddI8pDm48kB08p9-rNkpPD7A3fw8YFjZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIno0kSvzOWihTW1zp8-1-7mzYxUQjsVr2n3nmNdVcso4/bodyparts-skeleton.png?format=1000w)\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589410182515-9SJO9MML6CNCXBAWQ6Z6/ke17ZwdGBToddI8pDm48kJ1oJoOIxBAgRD2ClXVCmKFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxBw7VlGKDQO2xTcc51Yv6DahHgScLwHgvMZoEtbzk_9vMJY_JknNFgVzVQ2g0FD_s/ezgif.com-video-to-gif+%2811%29.gif?format=750w)\n",
        "\n",
        "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
        "\n",
        "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
        "\n",
        "Now it is the time to start training the network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eMeUwgxPoEJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "180ff570-4596-4c44-f2e1-08c50c38c717"
      },
      "source": [
        "# ATTENTION:\n",
        "\n",
        "#Note, you must run this. If your images are smaller than 400 by 400, please make these numbers smaller.\n",
        "deeplabcut.cropimagesandlabels(path_config_file, size=(400, 400), userfeedback=False)\n",
        "\n",
        "#if you labeled on Windows, please set the windows2linux=True:\n",
        "deeplabcut.create_multianimaltraining_dataset(path_config_file, windows2linux=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/maDLC_MM_hands2/maDLC_MM_hands-Brice-2021-07-08/labeled-data/Pil01_cropped  already exists!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-dc324ec7c7e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Note, you must run this. If your images are smaller than 400 by 400, please make these numbers smaller.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcropimagesandlabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserfeedback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#if you labeled on Windows, please set the windows2linux=True:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/generate_training_dataset/trainingsetmanipulation.py\u001b[0m in \u001b[0;36mcropimagesandlabels\u001b[0;34m(config, numcrops, size, userfeedback, cropdata, excludealreadycropped, updatevideoentries)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_sets_original\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mvidpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvidname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideotype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_robust_path_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labeled-data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvidname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ruamel/yaml/comments.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;31m# type: () -> Any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mordereddict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: OrderedDict mutated during iteration"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4FczXGDoEJU"
      },
      "source": [
        "## Start training:\n",
        "This function trains the network for a specific shuffle of the training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pOvDq_2oEJW"
      },
      "source": [
        "#let's also change the display and save_iters just in case Colab takes away the GPU... \n",
        "#if that happens, you can reload from a saved point. \n",
        "#Typically, you want to train to 50,000 iterations.\n",
        "#more info and there are more things you can set: https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/functionDetails.md#g-train-the-network\n",
        "\n",
        "#which shuffle do you want to train?\n",
        "shuffle = 1\n",
        "deeplabcut.train_network(path_config_file, shuffle=shuffle, displayiters=100, saveiters=2500, maxiters=20000)\n",
        "\n",
        "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 50K iterations). \n",
        "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiDwIVf5-3H_"
      },
      "source": [
        "**When you hit \"STOP\" you will get a KeyInterrupt \"error\"! No worries! :)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZygsb2DoEJc"
      },
      "source": [
        "## Start evaluating: for maDLC, this is several steps. \n",
        " - First, we evaluate the pose estimation performance, and then we can cross-valudate optimal inference parameters.\n",
        "\n",
        "- This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images) and stores the results as .5 and .csv file in a subdirectory under **evaluation-results**\n",
        "\n",
        "- If the scoremaps do not look accurate, don't proceed to tracklet assembly; please consider (1) adding more data, (2) adding more bodyparts!\n",
        "\n",
        "Here is an example of what you'd aim to see before proceeding:\n",
        "\n",
        "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590535809087-X655WY9W1MW1MY1I7DHE/ke17ZwdGBToddI8pDm48kBoswZhKnUtAF7-bTXgw67EUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc5tTP1cnANTUwNNPnYFjIp6XbP9N1GxIgAkxvBVqt0UvLpPHYwvNQTwHg8f_Zu8ZF/evaluation.png?format=1000w)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv4zlbrnoEJg"
      },
      "source": [
        "#let's evaluate first:\n",
        "deeplabcut.evaluate_network(path_config_file,Shuffles=[shuffle], plotting=True,c_engine=False)\n",
        "#plot a few scoremaps:\n",
        "deeplabcut.extract_save_all_maps(path_config_file, shuffle=shuffle, Indices=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYlGbloolDU2"
      },
      "source": [
        "IF these images, numbers, and maps do not look good, do not proceed. You should increase the diversity and number of frames you label, and re-create a training dataset and re-train! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MbIL5z2U7fp"
      },
      "source": [
        "NOTE: this optimized part detection for video analysis. It cannot optimze for tracking, as this is use-case dependent. Please check the docs on how you can set the best parameters and modify/test before \"final\" tracking parameters. You can use COLAB to analyze videos, but afterwards we recommend using the outputs/proejct folder locally to run the final steps! They do not require a GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s2SjwcIk-R9"
      },
      "source": [
        "#Cross-validate for Animal Assembly & Tracking:\n",
        "deeplabcut.evaluate_multianimal_crossvalidate(\n",
        "            path_config_file,\n",
        "            Shuffles=[shuffle],\n",
        "            edgewisecondition=True,\n",
        "            leastbpts=1,\n",
        "            init_points=20,\n",
        "            n_iter=100,\n",
        "            target='rpck_train',\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFLSKKfoEJk"
      },
      "source": [
        "## Start Analyzing videos: \n",
        "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
        "\n",
        "The results are stored in hd5 file in the same directory where the video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_LZiS_0oEJl"
      },
      "source": [
        "print(\"Start Analyzing my video(s)!\")\n",
        "scorername = deeplabcut.analyze_videos(path_config_file, \n",
        "                                       videofile_path, \n",
        "                                       shuffle=shuffle, \n",
        "                                       videotype=VideoType, \n",
        "                                       c_engine=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxRLS2_-r55K"
      },
      "source": [
        "## The steps below work on a single video at a time.\n",
        "- Here you can create a video to check the pose estimation detection quality! If this looks good, proceed to tracklet conversions with the interactive GUI (ouside of COLAB for now), or if you know your optimal parameters, you can automate this and run the additional steps shown in a few cells down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mWwX5bTc5C"
      },
      "source": [
        "##### PROTIP: #####\n",
        "## look at the output video; if the pose estimation (i.e. key points)\n",
        "##  don't look good, don't proceed with tracking - add more data to your training set and re-train!\n",
        "\n",
        "#let's check a specific video (PLEASE EDIT VIDEO PATH):\n",
        "Specific_videofile = '/content/drive/My Drive/yourproject/videos/demo.mp4'\n",
        "\n",
        "from deeplabcut.utils import auxiliaryfunctions\n",
        "scorername, DLCscorerlegacy = auxiliaryfunctions.GetScorerName(path_config_file, shuffle, trainFraction=0)\n",
        "print(\"scorename is: \"+scorername)\n",
        "\n",
        "deeplabcut.create_video_with_all_detections(path_config_file, [Specific_videofile], scorername)\n",
        "\n",
        "#Again, if this does not look perfect, do not proceed! Retrain with more diverse data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78x3BbotIsuO"
      },
      "source": [
        "## Convert Detections to Tracklets:\n",
        "\n",
        "- The idea is that you test and adapt hyperparameters for tracking outside of COLAB. Once you have good parameters, this can be automated on future videos. Shown here!\n",
        "\n",
        "- I.e., instead of always doing an interactive parameter setting step, you can simply convert tracklets to .h5 files using these parameters (see GitHub for more info)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIvXM7TXIs-U"
      },
      "source": [
        "#assemble tracklets:\n",
        "#read the docs: which tracker to test out (you can run this many times to try multiple):\n",
        "tracktype= 'box' #box, skeleton, ellipse\n",
        "\n",
        "deeplabcut.convert_detections2tracklets(path_config_file, Specific_videofile, videotype=VideoType,\n",
        "                                                    shuffle=shuffle, track_method=tracktype, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHH9lCM7JCZ0"
      },
      "source": [
        "## Now you should manually verify the tracks and correct them if needed! [currently only working outside of COLAB]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocRzxq7fJCjm"
      },
      "source": [
        "''' here is the code you would need:\n",
        "os.environ[\"DLClight\"]=\"False\"\n",
        "import deeplabcut\n",
        "\n",
        "#ATTENTION:\n",
        "picklefile = '/...._10000_bx.pickle' #(see your video folder for path i.e. right click and say copy path!!!)\n",
        "vid ='/yourVIDEO.mp4'\n",
        "#if you want occlusions filled in, tell us how many frames to fill in, i.e. if there is a gap in data:\n",
        "framestofill = 0. #note, put \"0\" if you want ALL gaps filled!\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from deeplabcut import refine_tracklets\n",
        "TrackletManager, TrackletVisualizer = refine_tracklets(path_config_file, \n",
        "                                                          picklefile, \n",
        "                                                          Specific_videofile, \n",
        "                                                          min_swap_frac=0,\n",
        "                                                          min_tracklet_frac=0, \n",
        "                                                          max_gap=framestofill)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUOKrLJRseUX"
      },
      "source": [
        "## Let's assume you have great tracking parameters, and you want to analyze a full set of videos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6izVWX8sdzL"
      },
      "source": [
        "#^^^^^^^^^You do NOT neeed to run if you hit \"save\" in the GUI ^^^^^^^^^^\n",
        "#this is just if you want to run the same parameters over a set of videos!\n",
        "\n",
        "# You need to point to your pickle file, please \"copy path\" from the folder to the left (right click, copy path)\n",
        "picklefile = '/content/drive/My Drive/mwm-penguins-2020-03-31/videos/penguindemoDLC_resnet50_mwmMar31shuffle1_22000_bx.pickle' #(see your video folder for path i.e. right click and say copy path!!!)\n",
        "vid ='/content/drive/My Drive/mwm-penguins-2020-03-31/videos/penguindemo.mp4'\n",
        "\n",
        "deeplabcut.convert_raw_tracks_to_h5(path_config_file, picklefile)\n",
        "deeplabcut.filterpredictions(path_config_file, \n",
        "                                 videofile_path, \n",
        "                                 videotype=VideoType, \n",
        "                                 track_method = tracktype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk4xGb8Ftf3B"
      },
      "source": [
        "## Create plots of your trajectories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX21zZbXoEKJ"
      },
      "source": [
        "deeplabcut.plot_trajectories(path_config_file,videofile_path, videotype=VideoType, track_method=tracktype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqaCw15v8EmB"
      },
      "source": [
        "Now you can look at the plot-poses file and check the \"plot-likelihood.png\" might want to change the \"p-cutoff\" in the config.yaml file so that you have only high confidnece points plotted in the video. i.e. ~0.8 or 0.9. The current default is 0.4. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCrUvQIvoEKD"
      },
      "source": [
        "## Create labeled video:\n",
        "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDF7Q7KoEKE"
      },
      "source": [
        "deeplabcut.create_labeled_video(path_config_file,\n",
        "                                videofile_path, \n",
        "                                shuffle=shuffle, \n",
        "                                draw_skeleton=True, \n",
        "                                videotype=VideoType, \n",
        "                                save_frames=False,\n",
        "                                filtered=True, \n",
        "                                track_method = tracktype)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}